{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import csv\n",
    "#from compmusic import dunya\n",
    "import music21\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#dunya.set_token(\"52fc6ac49c0b7fc9644404aaf4f9bc1a7088d69d\")\n",
    "\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import patterns_per_nawba as pn\n",
    "import nawba_centones\n",
    "import classification as cl\n",
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nawba mappings to centones\n",
    "nawba_centones_lookup = nawba_centones.load_and_parse_centones_mapping(os.path.join(data_path, 'centones_nawba.csv'))\n",
    "\n",
    "# list of scores to parse\n",
    "andalusian_description =  pd.read_json(os.path.join(data_path, 'andalusian_description.json'))\n",
    "\n",
    "# mbid mappings to nawbas\n",
    "nawba_tabs = nawba_centones.load_and_parse_nawba_tabs(os.path.join(data_path, 'nawba_tabs.json'))\n",
    "mbid_tab_lookup = pn.mbids_per_tab(andalusian_description)\n",
    "mbid_nawba_lookup = pn.mbids_per_nawba(mbid_tab_lookup, nawba_tabs)\n",
    "\n",
    " # score sections lookup   \n",
    "score_annotations_lookup = pn.score_annotations_lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "istihlal_mbids = [mbid for mbid in mbid_nawba_lookup if mbid_nawba_lookup[mbid] == '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_stream_from_score_section(path, offsets, rest_quarter_length=0):\n",
    "    \"\"\"\n",
    "    Load a score from <path> and return an ordered list of notes\n",
    "    R represents a rest greater than or equal to <rest_quarter_length>\n",
    "    ...rests shorter than <rest_quarter_length> are ignored\n",
    "\n",
    "    Fails if score contains chords\n",
    "    \"\"\"\n",
    "\n",
    "    s = music21.converter.parse(path)\n",
    "    p = s.parts[0]\n",
    "    section = p.getElementsByOffset(float(offsets[0]), float(offsets[1]),\n",
    "                                    mustBeginInSpan=False,\n",
    "                                    includeElementsThatEndAtStart=False).stream()\n",
    "    # These are all the notes of the whole piece, fails for chords\n",
    "    notes_and_rests = section.flat.notesAndRests.stream()\n",
    "    notes = []\n",
    "    for n in notes_and_rests:\n",
    "        if n.isRest:\n",
    "            notes.append('R')\n",
    "        else:\n",
    "            notes.append(n.name)\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes_from_score_section(scores_path, mbid_nawba_lookup):\n",
    "    \"\"\"\n",
    "    Function that return a dict with mbid: all notes of a score\n",
    "    :param scores_path: path where the scores are saved\n",
    "    :return: described dict\n",
    "    \"\"\"\n",
    "    notes_dict = {}\n",
    "    chord_mbid = []\n",
    "    for root, dirs, files in os.walk(scores_path):\n",
    "        for file in files:\n",
    "            mbid = file.replace('.xml','')\n",
    "            if mbid in istihlal_mbids:\n",
    "                if mbid in score_annotations_lookup:\n",
    "                    notes_dict[mbid] = {}\n",
    "                    for sections in score_annotations_lookup[mbid]:\n",
    "                        for offsets in score_annotations_lookup[mbid][sections]:\n",
    "                            # Fails for scores with chords\n",
    "                            try:\n",
    "                                note_stream = pattern_stream_from_score_section(os.path.join(scores_path,file), offsets)\n",
    "                            except Exception as e:\n",
    "                                print('{} contains chords and wont be counted'.format(mbid))\n",
    "                                chord_mbid.append(mbid)\n",
    "                            if sections not in notes_dict[mbid]:\n",
    "                                notes_dict[mbid][sections] = [note_stream]\n",
    "                            else:\n",
    "                                notes_dict[mbid][sections].append(note_stream)\n",
    "    return notes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = '../data/scores_xml/'\n",
    "notes_dict = get_notes_from_score_section(scores_path, mbid_nawba_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern_grams(notes, min_n=2, max_n=2):\n",
    "    \"\"\"\n",
    "    For a list of list of notes, <notes>\n",
    "    Extract all possible note-grams up to a maximum length of <n>\n",
    "    Converts stream of notes to bag-of-patterns\n",
    "    \"\"\"\n",
    "    num_notes = len(notes)\n",
    "    comb  = []\n",
    "    for i in range(num_notes):\n",
    "        # Final n patterns are counted more than once\n",
    "        n_ = num_notes - i if max_n > num_notes - i else max_n\n",
    "        comb.append([notes[i:i+j] for j in range(2,n_+1)])\n",
    "    flat = [i for c in comb for i in c]\n",
    "    return ' '.join([''.join(x) for x in flat if len(x) >= min_n if 'R' not in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_patterns = []\n",
    "for mbid in notes_dict:\n",
    "    for sections in notes_dict[mbid]:\n",
    "        for section in notes_dict[mbid][sections]:\n",
    "            sections_patterns.append([sections, extract_pattern_grams(section, min_n=3, max_n=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import seaborn as sn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_tfidf_distributions(all_recordings):\n",
    "    \"\"\"\n",
    "    For a list of all recordings patterns tf-df-results\n",
    "    Returns:\n",
    "        list, each elecment a recording, summarised as a list of (pattern, tf-idf, total_count_of_pattern)\n",
    "    \"\"\"\n",
    "    token_pattern = '[A-a0-9#-]*'\n",
    "    vectorizer = TfidfVectorizer(lowercase=False, sublinear_tf=True, token_pattern=token_pattern)\n",
    "    X = vectorizer.fit_transform(all_recordings)\n",
    "    top_patterns = []\n",
    "    sorted_vocab = sorted([(k,v) for k,v in vectorizer.vocabulary_.items()], key=lambda y: y[1])\n",
    "    vocab = [x[0] for x in sorted_vocab]\n",
    "    for i,x in enumerate(X):\n",
    "        weights = x.toarray()[0]\n",
    "        pattern_counts = Counter(all_recordings[i].split(' '))\n",
    "        this_patterns = []\n",
    "        for v,w in zip(vocab, weights):\n",
    "            tf = float(pattern_counts[v])/len(pattern_counts)\n",
    "            this_patterns.append((v, tf*w, pattern_counts[v]))\n",
    "        top_patterns.append(this_patterns)\n",
    "    return top_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_patterns = [x[1] for x in sections_patterns]\n",
    "distributions = get_tfidf_distributions(only_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tfidf(distributions, indices):\n",
    "    \"\"\"\n",
    "    For a list of tfidf results (from model.get_tfidf_distributions)\n",
    "    Return:\n",
    "        Dataframe of average tf-idf across recordings of the same nawba\n",
    "        ...[nawba, pattern, tf-idf, frequency]\n",
    "    \"\"\"\n",
    "    frame = zip_nawba(distributions, indices)\n",
    "    frame_grouped = frame.groupby(['index', 'pattern'])\\\n",
    "                         .agg({'tf-idf': 'mean', 'frequency': 'sum'})\\\n",
    "                         .reset_index()\n",
    "    return frame_grouped\n",
    "\n",
    "\n",
    "def zip_nawba(distributions, indices):\n",
    "    \"\"\"\n",
    "    Convert distributions output to DF\n",
    "    \"\"\"\n",
    "    zip_nawba = [\n",
    "        [(n,x,y,z) for x,y,z in d] \\\n",
    "        for n,d in zip(indices, distributions)\n",
    "    ]\n",
    "    frame = pd.DataFrame(\n",
    "        [y for x in zip_nawba for y in x],\n",
    "        columns=['index', 'pattern', 'tf-idf', 'frequency']\n",
    "    )\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_grouped = average_tfidf(distributions, [x[0] for x in sections_patterns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pattern</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inṣirāf</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inṣirāf</td>\n",
       "      <td>AAA</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inṣirāf</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inṣirāf</td>\n",
       "      <td>AAAAA</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inṣirāf</td>\n",
       "      <td>AAAAAG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index pattern    tf-idf  frequency\n",
       "0  inṣirāf          0.000000          0\n",
       "1  inṣirāf     AAA  0.000918        261\n",
       "2  inṣirāf    AAAA  0.000157         49\n",
       "3  inṣirāf   AAAAA  0.000005          6\n",
       "4  inṣirāf  AAAAAG  0.000000          0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_sections = [x[0] for x in sections_patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = zip_nawba(distributions, corresponding_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sections = mylist = list(dict.fromkeys(corresponding_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_patterns={}\n",
    "for section in list_of_sections:\n",
    "    cont = 0\n",
    "    this_frame = frame_grouped[(frame_grouped['index'] == section)].sort_values(by='tf-idf', ascending=False)\n",
    "    likely_patterns = this_frame[['pattern','tf-idf']]\n",
    "    likely_patterns = likely_patterns.values.tolist()\n",
    "    if section not in section_patterns:\n",
    "        section_patterns[section]=[]\n",
    "    for pattern in likely_patterns[:10]:\n",
    "        section_patterns[section].append(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mišālia': [['FED', 0.009530580064484246],\n",
       "  ['EFEF', 0.00829734543768562],\n",
       "  ['EFE', 0.007039243271887708],\n",
       "  ['FEF', 0.006986637522275103],\n",
       "  ['EDC', 0.006164799488139136],\n",
       "  ['EDCCC', 0.004882118272167268],\n",
       "  ['FFE', 0.004676779908171378],\n",
       "  ['EDDD', 0.004618212917938627],\n",
       "  ['EFEFEF', 0.004618212917938627],\n",
       "  ['EFEFEFG', 0.004618212917938627]],\n",
       " 'tawāšī': [['GFE', 0.0020476265045236215],\n",
       "  ['FED', 0.0019639628936384567],\n",
       "  ['EDC', 0.0019002177842133712],\n",
       "  ['GFED', 0.001673350500404252],\n",
       "  ['CDE', 0.0014946541002338859],\n",
       "  ['FEDC', 0.0013957618269212877],\n",
       "  ['FGF', 0.0013104573950982574],\n",
       "  ['GFEDC', 0.00109094090639226],\n",
       "  ['EFG', 0.0010308892241602035],\n",
       "  ['DEF', 0.0010277736580738626]],\n",
       " 'muassa‘': [['GFE', 0.003878961510190407],\n",
       "  ['FED', 0.0034924822460849422],\n",
       "  ['EDC', 0.0031487058541129656],\n",
       "  ['GFED', 0.002814542950432407],\n",
       "  ['FEDC', 0.002693035864410414],\n",
       "  ['AGF', 0.0021606590941116214],\n",
       "  ['AGFE', 0.002150209905477527],\n",
       "  ['EFG', 0.0019748752584738223],\n",
       "  ['GFEDC', 0.0019080114095281848],\n",
       "  ['CDE', 0.0017003813958964447]],\n",
       " 'mahzūz': [['FED', 0.005200443730128248],\n",
       "  ['EDC', 0.0046981066675088725],\n",
       "  ['GFED', 0.0046371553649847234],\n",
       "  ['GFE', 0.004379426553591975],\n",
       "  ['FEDC', 0.003926274646861327],\n",
       "  ['GFEDC', 0.003260284450754803],\n",
       "  ['AGFE', 0.002914625646073495],\n",
       "  ['AGFED', 0.0029113349804534565],\n",
       "  ['CDE', 0.0025943684556262226],\n",
       "  ['AGF', 0.002515940150996057]],\n",
       " 'inṣirāf': [['GFE', 0.0034115850626905077],\n",
       "  ['CDE', 0.003245429941611591],\n",
       "  ['EDC', 0.0031974575741156902],\n",
       "  ['FED', 0.0028451434155187263],\n",
       "  ['GFED', 0.0027428763528904295],\n",
       "  ['CBCDE', 0.0022751536451580405],\n",
       "  ['CBCDEDE', 0.0022275108822858523],\n",
       "  ['BCDEDE', 0.0022275108822858523],\n",
       "  ['DED', 0.002140860604735435],\n",
       "  ['EDE', 0.002129339532659387]]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(df, nawba_groups):\n",
    "    patterns = [i for s in nawba_groups.values() for i in s]\n",
    "            \n",
    "    frame = df[df['pattern'].isin(patterns)]\n",
    "    data = frame.pivot_table(values='frequency', columns='pattern', index='index')\\\n",
    "                 .reset_index()\n",
    "    #mbid_nawba_dict = {x:y for x,y in mbid_nawba}\n",
    "    #data['index'] = data['index'].apply(lambda y: mbid_nawba_dict[y])\n",
    "        \n",
    "    train, test = train_test_split(data, test_size=0.6)\n",
    "    \n",
    "    y = train['index']\n",
    "    X = train[[x for x in patterns if x in train.columns]]\n",
    "    \n",
    "    clf = LogisticRegression(\n",
    "        random_state=42,\n",
    "        C=0.01,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr'\n",
    "    ).fit(X, y)\n",
    "    \n",
    "    test_preds = clf.predict(test[[x for x in patterns if x in test.columns]])\n",
    "    y_true = test['index']\n",
    "    \n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #sn.heatmap(confusion_matrix(test_preds, y_true))\n",
    "    \n",
    "    return accuracy_score(test_preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-045cf842e862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mour_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_patterns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-045cf842e862>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mour_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_patterns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-4ff9613babc8>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(df, nawba_groups)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnawba_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frequency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pattern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#mbid_nawba_dict = {x:y for x,y in mbid_nawba}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miguelgc96/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   4001\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4002\u001b[0m         \"\"\"\n\u001b[0;32m-> 4003\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4004\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miguelgc96/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mcomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/miguelgc96/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# faster for larger cases to use np.in1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismember_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# GH16012\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_func_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.ismember_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "our_results = [train_classifier(df, section_patterns) for x in range(100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
